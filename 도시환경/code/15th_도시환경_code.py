# -*- coding: utf-8 -*-
"""15th_ÎèÑÏãúÌôòÍ≤Ω_code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vJVI57oAJHjQQMpzqM4QHkimVwYKRM2t

## ÎÇ†Ïî®
"""

import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
plt.rcParams['font.family'] = 'Malgun Gothic'  # ÏúàÎèÑÏö∞ Í∏∞Î≥∏ ÌïúÍ∏Ä Ìè∞Ìä∏
plt.rcParams['axes.unicode_minus'] = False     # ÎßàÏù¥ÎÑàÏä§(-) Íπ®Ïßê Î∞©ÏßÄ

BASE = Path(__file__).resolve().parent
csv_path = BASE / "ÏùºÎ≥Ñ_ÎÇ†Ïî®_Îç∞Ïù¥ÌÑ∞(2023~2025).csv"


df = pd.read_csv(csv_path, encoding="utf-8-sig")
print(df.tail())

df_clean = df.copy()
df_clean['ÏùºÍ∞ïÏàòÎüâ(mm)'] = df_clean['ÏùºÍ∞ïÏàòÎüâ(mm)'].fillna(0) #Í≤∞Ï∏°ÏπòÎäî Î™®Îëê 0ÏúºÎ°ú Ï≤òÎ¶¨

# Í∏∞Ïò® - ÎåÄÏó¨Í±¥Ïàò
df_clean['temp_int'] = np.floor(df_clean['ÌèâÍ∑†Í∏∞Ïò®(¬∞C)']).astype(int) # ex)25.0ÏôÄ 25.9 Îäî Í∞ôÏùÄ 25Î°ú Ï∑®Í∏â
temp_group = (
    df_clean
    .groupby('temp_int')['ÎåÄÏó¨Í±¥Ïàò']
    .mean()
    .sort_index()
)

#ÏÑ† Í∑∏ÎûòÌîÑ
plt.figure()
temp_group.plot(kind='line',color="#7D6CA8", marker='o')
plt.xlabel('Í∏∞Ïò® (¬∞C)')
plt.ylabel('ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò')
plt.title('Í∏∞Ïò® Íµ¨Í∞ÑÎ≥Ñ ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò(2023-2025)')
plt.tight_layout()
plt.show()

#ÎßâÎåÄ Í∑∏ÎûòÌîÑ
plt.figure(figsize = (8,4))
temp_group.plot(kind='bar',color="#7D6CA8")
plt.xlabel('Í∏∞Ïò® (¬∞C)')
plt.ylabel('ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò')
plt.title('Í∏∞Ïò® Íµ¨Í∞ÑÎ≥Ñ ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò(2023-2025)')
plt.xticks(rotation = 90)
plt.tight_layout()
plt.show()

# ÌíçÏÜç - ÎåÄÏó¨Í±¥Ïàò
df_clean = df_clean[(df_clean['ÌèâÍ∑† ÌíçÏÜç(m/s)'] >= 1.4) & (df_clean['ÌèâÍ∑† ÌíçÏÜç(m/s)'] <= 3.7)]
wind_group = (
    df_clean
    .groupby('ÌèâÍ∑† ÌíçÏÜç(m/s)')['ÎåÄÏó¨Í±¥Ïàò']
    .mean()
    .sort_index()
)

# ÏÑ† Í∑∏ÎûòÌîÑ
plt.figure(figsize=(5, 5))
wind_group.plot(kind='line',color="#7D6CA8", marker='o')
plt.xlabel('ÌíçÏÜç(m/s)')
plt.ylabel('ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò')
plt.title('ÌíçÏÜç Íµ¨Í∞ÑÎ≥Ñ ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò')
plt.tight_layout()
plt.show()

# ÎßâÎåÄ Í∑∏ÎûòÌîÑ
plt.figure(figsize=(5, 5))
wind_group.plot(kind='bar',color="#7D6CA8")
plt.xlabel('ÌíçÏÜç(m/s)')
plt.ylabel('ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò')
plt.title('ÌíçÏÜç Íµ¨Í∞ÑÎ≥Ñ ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

# Í∞ïÏàòÎüâ - ÎåÄÏó¨Í±¥Ïàò
df_clean['rain_bin'] = pd.cut(
    df_clean['ÏùºÍ∞ïÏàòÎüâ(mm)'],
    bins=[-0.1, 0, 1, 3, 5, 10, 20, float('inf')],
    labels=['Î¨¥Í∞ïÏàò', '0~1mm', '1~3mm', '3~5mm', '5~10mm', '10~20mm', '20mm Ïù¥ÏÉÅ']
)

rain_group = (
    df_clean
    .groupby('rain_bin', observed=True)['ÎåÄÏó¨Í±¥Ïàò']
    .mean()
)

# ÎßâÎåÄ Í∑∏ÎûòÌîÑ
plt.figure(figsize=(7, 5))
rain_group.plot(kind='bar', color="#7D6CA8")
plt.xlabel('Í∞ïÏàòÎüâ(mm)')
plt.ylabel('ÌèâÍ∑† Îî∞Î¶âÏù¥ ÎåÄÏó¨Í±¥Ïàò')
plt.title('Í∞ïÏàòÎüâ Íµ¨Í∞ÑÎ≥Ñ ÌèâÍ∑† Îî∞Î¶âÏù¥ ÎåÄÏó¨Í±¥Ïàò')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

# Í∞ïÏàò Ïó¨Î∂ÄÎ°ú Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨
no_rain = df_clean.loc[df_clean['ÏùºÍ∞ïÏàòÎüâ(mm)'] == 0, 'ÎåÄÏó¨Í±¥Ïàò'].dropna()
rain    = df_clean.loc[df_clean['ÏùºÍ∞ïÏàòÎüâ(mm)'] > 0,  'ÎåÄÏó¨Í±¥Ïàò'].dropna()

# Î∞ïÏä§ÌîåÎ°Ø
plt.figure(figsize=(5, 4))
plt.boxplot([no_rain, rain], tick_labels=['Í∞ïÏàòX (=0mm)', 'Í∞ïÏàòO (>0mm)'])
plt.title('Í∞ïÏàò Ïó¨Î∂ÄÏóê Îî∞Î•∏ Îî∞Î¶âÏù¥ ÎåÄÏó¨Í±¥Ïàò ÎπÑÍµê')
plt.ylabel('ÏùºÎ≥Ñ Îî∞Î¶âÏù¥ ÎåÄÏó¨Í±¥Ïàò(usage)')
plt.tight_layout()
plt.show()

# ÏöîÏïΩ ÌÜµÍ≥Ñ Ï∂úÎ†•
mean_no_rain = no_rain.mean()
mean_rain = rain.mean()
std_no_rain = no_rain.std(ddof=1)
std_rain = rain.std(ddof=1)

decrease_pct = (1 - mean_rain / mean_no_rain) * 100

print(f"ÎπÑÍ∞Ä ÏïàÏôîÏùÑÎïå ÌèâÍ∑† Ïù¥Ïö©Îüâ: {mean_no_rain:.0f}")
print(f"ÎπÑÍ∞Ä ÏôîÏùÑÎïå ÌèâÍ∑† Ïù¥Ïö©Îüâ: {mean_rain:.0f}")
print(f"ÎπÑÍ∞Ä ÏïàÏôîÏùÑÎïå Ïù¥Ïö©ÎüâÏùò ÌëúÏ§ÄÌé∏Ï∞®: {std_no_rain:.0f}")
print(f"ÎπÑÍ∞Ä ÏôîÏùÑÎïå Ïù¥Ïö©ÎüâÏùò ÌëúÏ§ÄÌé∏Ï∞®: {std_rain:.0f}")
print(f"Ïù¥Ïö©Îüâ Í∞êÏÜåÏú®(%): {decrease_pct:.2f}")

plt.figure(figsize=(5,4))
plt.hist(no_rain, bins=30, density=True, alpha=0.4, color="#7D6CA8", label="Í∞ïÏàòX (=0mm)")
plt.hist(rain,    bins=30, density=True, alpha=0.4, color="#FFC107", label="Í∞ïÏàòO (>0mm)")
plt.xlabel("ÎåÄÏó¨Í±¥Ïàò")
plt.ylabel("Î∞ÄÎèÑ(density)")
#plt.title("Í∞ïÏàò Ïó¨Î∂ÄÏóê Îî∞Î•∏ ÎåÄÏó¨Í±¥Ïàò Î∂ÑÌè¨ ÎπÑÍµê")
plt.legend(frameon=False,loc="upper right",fontsize=8)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# ÎØ∏ÏÑ∏Î®ºÏßÄ - ÎåÄÏó¨Í±¥Ïàò
df_clean['pm_int'] = np.floor(df_clean['ÎØ∏ÏÑ∏Î®ºÏßÄ(PM10)']).astype(int)
pm_group = (
    df_clean
    .groupby('pm_int')['ÎåÄÏó¨Í±¥Ïàò']
    .mean()
    .sort_index()
)

# ÏÑ† Í∑∏ÎûòÌîÑ
plt.figure(figsize=(10, 5))
pm_group.plot(kind='line', color="#7D6CA8", marker='o')
plt.xlabel('ÎØ∏ÏÑ∏Î®ºÏßÄ(PM10) ÎÜçÎèÑ (¬µg/m¬≥)')
plt.ylabel('ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò')
plt.title('ÎØ∏ÏÑ∏Î®ºÏßÄ(PM10) ÎÜçÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò(2023-2025)')
plt.tight_layout()
plt.show()

# ÎßâÎåÄ Í∑∏ÎûòÌîÑ
plt.figure(figsize=(12, 5))
pm_group.plot(kind='bar', color="#7D6CA8")
plt.xlabel('ÎØ∏ÏÑ∏Î®ºÏßÄ(PM10) ÎÜçÎèÑ (¬µg/m¬≥)')
plt.ylabel('ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò')
plt.title('ÎØ∏ÏÑ∏Î®ºÏßÄ(PM10) ÎÜçÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌèâÍ∑† ÎåÄÏó¨Í±¥Ïàò(2023-2025)')
plt.xticks()
plt.tight_layout()
plt.show()

# ÎØ∏ÏÑ∏Î®ºÏßÄ - ÎåÄÏó¨Í±¥Ïàò
df_clean['pm_bin'] = pd.cut(
    df_clean['ÎØ∏ÏÑ∏Î®ºÏßÄ(PM10)'],
    bins=[-0.1, 30, 80, 150, float('inf')],
    labels=['Ï¢ãÏùå(0~30)', 'Î≥¥ÌÜµ(31~80)', 'ÎÇòÏÅ®(81~150)', 'Îß§Ïö∞ ÎÇòÏÅ®(151~)']
)

pm_good = df_clean.loc[df_clean['pm_bin'] == 'Ï¢ãÏùå(0~30)', 'ÎåÄÏó¨Í±¥Ïàò']
pm_normal = df_clean.loc[df_clean['pm_bin'] == 'Î≥¥ÌÜµ(31~80)', 'ÎåÄÏó¨Í±¥Ïàò']
pm_bad = df_clean.loc[df_clean['pm_bin'] == 'ÎÇòÏÅ®(81~150)', 'ÎåÄÏó¨Í±¥Ïàò']
pm_very_bad = df_clean.loc[df_clean['pm_bin'] == 'Îß§Ïö∞ ÎÇòÏÅ®(151~)', 'ÎåÄÏó¨Í±¥Ïàò']

# Î∞ïÏä§ ÌîåÎ°Ø
plt.figure(figsize=(10, 4))
plt.boxplot(
    [pm_good, pm_normal, pm_bad, pm_very_bad],
    tick_labels=['Ï¢ãÏùå(0~30)', 'Î≥¥ÌÜµ(31~80)', 'ÎÇòÏÅ®(81~150)', 'Îß§Ïö∞ ÎÇòÏÅ®(151~)']
)

plt.title('ÎØ∏ÏÑ∏Î®ºÏßÄ ÏàòÏ§ÄÏóê Îî∞Î•∏ Îî∞Î¶âÏù¥ ÎåÄÏó¨Í±¥Ïàò ÎπÑÍµê(2023-2025)')
plt.ylabel('ÏùºÎ≥Ñ Îî∞Î¶âÏù¥ ÎåÄÏó¨Í±¥Ïàò')
plt.tight_layout()
plt.show()

"""## ÏãúÍ∞ÑÎåÄ"""

#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import os, glob, zipfile, csv
import pandas as pd
import numpy as np
from collections import defaultdict
from io import TextIOWrapper

BASE_DIR = r"C:\Users\Ïù¥Ïú§ÏÑú\Documents\YONSEI\DSL\26-1"
OUT_DIR  = os.path.join(BASE_DIR, "output")
os.makedirs(OUT_DIR, exist_ok=True)

def normalize_date_str(s: str) -> str:
    s = str(s).strip()
    if len(s) == 8 and s.isdigit():
        return f"{s[:4]}-{s[4:6]}-{s[6:8]}"
    return s

date_cache = {}
def get_date_info(date_str: str):
    ds = normalize_date_str(date_str)
    if ds in date_cache:
        return date_cache[ds]
    dt = pd.to_datetime(ds, errors="coerce")
    if pd.isna(dt):
        return None
    month = dt.strftime("%Y-%m")
    weekday = int(dt.dayofweek)
    weekday_type = "weekend" if weekday >= 5 else "weekday"
    date_cache[ds] = (month, weekday, weekday_type)
    return date_cache[ds]

def parse_hour(val) -> int | None:
    t = str(val).strip()
    if not t:
        return None
    m = "".join([ch for ch in t if ch.isdigit()])
    if not m:
        return None
    try:
        x = int(m)
    except:
        return None
    if x <= 23:
        return x
    if x <= 2359:
        return x // 100
    if x <= 1440:
        return x // 60
    if x <= 300:
        return (x * 5) // 60
    return x % 24

def read_rows_from_member(z: zipfile.ZipFile, member: str):
    raw = z.open(member)
    tf = TextIOWrapper(raw, encoding="cp949", errors="ignore", newline="")
    first = tf.readline()
    if not first:
        tf.close(); raw.close()
        return None, None

    delim = "\t" if "\t" in first else ","
    header = [h.strip() for h in first.strip().split(delim)]
    col = {h: i for i, h in enumerate(header)}

    need = ["Í∏∞Ï§Ä_ÎÇ†Ïßú", "Í∏∞Ï§Ä_ÏãúÍ∞ÑÎåÄ", "ÏßëÍ≥Ñ_Í∏∞Ï§Ä", "Ï†ÑÏ≤¥_Í±¥Ïàò"]
    if not all(k in col for k in need):
        tf.close(); raw.close()
        return None, None

    reader = csv.reader(tf, delimiter=delim)
    return (col, reader, tf, raw)

def make_pivot(d, index_cols):
    tmp = pd.DataFrame(list(d.keys()), columns=index_cols + ["basis"])
    tmp["cnt"] = list(d.values())
    p = (tmp.pivot_table(index=index_cols, columns="basis", values="cnt", fill_value=0)
           .reset_index()
           .rename(columns={"Ï∂úÎ∞úÏãúÍ∞Ñ":"RentCnt", "ÎèÑÏ∞©ÏãúÍ∞Ñ":"RtnCnt"}))
    if "RentCnt" not in p.columns: p["RentCnt"] = 0
    if "RtnCnt" not in p.columns: p["RtnCnt"] = 0
    return p

def add_metrics(p):
    p["Net"] = p["RtnCnt"] - p["RentCnt"]
    p["Volume"] = p["RtnCnt"] + p["RentCnt"]
    p["NNF"] = np.where(p["Volume"] > 0, p["Net"]/p["Volume"], 0.0)
    p["BR"] = np.where(p["RentCnt"] > 0, p["RtnCnt"]/p["RentCnt"], np.nan)
    p["Risk"] = np.abs(p["NNF"]) * np.log1p(p["Volume"])
    return p

def build_year_summaries(year: int):
    agg_month = defaultdict(int)
    agg_hour  = defaultdict(int)
    agg_wdh   = defaultdict(int)

    zip_glob = os.path.join(BASE_DIR, f"tpss_bcycl_od_statnhm_{year}*.zip")
    zip_paths = sorted(glob.glob(zip_glob))
    if not zip_paths:
        raise FileNotFoundError(f"ZIP not found: {zip_glob}")

    for zp in zip_paths:
        with zipfile.ZipFile(zp) as z:
            names = [n for n in z.namelist() if n.lower().endswith(".csv")]
            for name in names:
                opened = read_rows_from_member(z, name)
                if opened[0] is None:
                    continue

                col, reader, tf, raw = opened
                i_date = col["Í∏∞Ï§Ä_ÎÇ†Ïßú"]
                i_time = col["Í∏∞Ï§Ä_ÏãúÍ∞ÑÎåÄ"]
                i_basis = col["ÏßëÍ≥Ñ_Í∏∞Ï§Ä"]
                i_cnt = col["Ï†ÑÏ≤¥_Í±¥Ïàò"]

                for row in reader:
                    if len(row) <= max(i_date, i_time, i_basis, i_cnt):
                        continue

                    info = get_date_info(row[i_date])
                    if info is None:
                        continue
                    month, weekday, weekday_type = info

                    hour = parse_hour(row[i_time])
                    if hour is None or not (0 <= hour <= 23):
                        continue

                    basis = str(row[i_basis]).strip()
                    try:
                        cnt = int(float(str(row[i_cnt]).strip()))
                    except:
                        continue

                    agg_month[(month, basis)] += cnt
                    agg_hour[(weekday_type, hour, basis)] += cnt
                    agg_wdh[(weekday, hour, basis)] += cnt

                tf.close(); raw.close()

    month_df = add_metrics(make_pivot(agg_month, ["month"])).sort_values("month").reset_index(drop=True)
    hour_df  = add_metrics(make_pivot(agg_hour, ["weekday_type","hour"])).sort_values(["weekday_type","hour"]).reset_index(drop=True)
    wdh_df   = add_metrics(make_pivot(agg_wdh, ["weekday","hour"])).sort_values(["weekday","hour"]).reset_index(drop=True)

    weekday_kr = {0:"Mon(Ïõî)",1:"Tue(Ìôî)",2:"Wed(Ïàò)",3:"Thu(Î™©)",4:"Fri(Í∏à)",5:"Sat(ÌÜ†)",6:"Sun(Ïùº)"}
    wdh_df["weekday_name"] = wdh_df["weekday"].map(weekday_kr)

    month_path = os.path.join(OUT_DIR, f"month_summary_{year}.csv")
    hour_path  = os.path.join(OUT_DIR, f"hourly_profile_{year}.csv")
    wdh_path   = os.path.join(OUT_DIR, f"hourly_by_weekday_{year}.csv")

    month_df.to_csv(month_path, index=False, encoding="utf-8-sig")
    hour_df.to_csv(hour_path, index=False, encoding="utf-8-sig")
    wdh_df.to_csv(wdh_path, index=False, encoding="utf-8-sig")

    return month_path, hour_path, wdh_path

for y in [2023, 2024, 2025]:
    print(build_year_summaries(y))


# In[ ]:


import os
import pandas as pd
import matplotlib.pyplot as plt

BASE_DIR = r"C:\Users\Ïù¥Ïú§ÏÑú\Documents\YONSEI\DSL\26-1\output"
paths = {
    2023: os.path.join(BASE_DIR, "month_summary_2023.csv"),
    2024: os.path.join(BASE_DIR, "month_summary_2024.csv"),
    2025: os.path.join(BASE_DIR, "month_summary_2025.csv"),
}

YEAR_COLOR = {2023:"#260A6E", 2024:"#7D6CA8", 2025:"#BAB5D3"}

dfs = []
metric = None
for y, p in paths.items():
    df = pd.read_csv(p)
    df["month_dt"] = pd.to_datetime(df["month"], format="%Y-%m", errors="coerce")
    df = df.dropna(subset=["month_dt"]).copy()
    df["m"] = df["month_dt"].dt.month
    df["year"] = y
    metric = "Volume" if "Volume" in df.columns else "RentCnt"
    df["value"] = df[metric]
    dfs.append(df[["year","m","value"]])

data = pd.concat(dfs, ignore_index=True).groupby(["year","m"], as_index=False)["value"].sum()

fig, ax = plt.subplots(figsize=(13.5, 7.6), dpi=200)
ax.grid(alpha=0.25)

ax.axvspan(0.5, 2.5, alpha=0.12, color="#9A9494", label="ÎπÑÏàòÍ∏∞(Í≤®Ïö∏: 12~2Ïõî)")
ax.axvspan(11.5, 12.5, alpha=0.12, color="#9A9494")

ax.axvspan(3.5, 6.5, alpha=0.12, color="#BAB5D3", label="ÌîºÌÅ¨ Íµ¨Í∞Ñ(4~6Ïõî, 9~10Ïõî)")
ax.axvspan(8.5, 10.5, alpha=0.12, color="#BAB5D3")

for y in sorted(data["year"].unique()):
    sub = data[data["year"] == y].sort_values("m")
    ax.plot(sub["m"], sub["value"], marker="o", linewidth=3, label=str(y), color=YEAR_COLOR[y])

ax.set_xticks(range(1, 13))
ax.set_xlabel("Month")
ax.set_ylabel(f"Monthly Usage ({metric})")
ax.legend(loc="upper right", frameon=True)

out_path = os.path.join(BASE_DIR, "monthly_usage_season_band.png")
plt.tight_layout()
plt.savefig(out_path, dpi=300, bbox_inches="tight")
plt.show()


# In[ ]:


import os
import pandas as pd
import matplotlib.pyplot as plt

BASE_DIR = r"C:\Users\Ïù¥Ïú§ÏÑú\Documents\YONSEI\DSL\26-1\output"
paths = {
    2023: os.path.join(BASE_DIR, "hourly_profile_2023.csv"),
    2024: os.path.join(BASE_DIR, "hourly_profile_2024.csv"),
    2025: os.path.join(BASE_DIR, "hourly_profile_2025.csv"),
}
YEAR_COLOR = {2023:"#260A6E", 2024:"#7D6CA8", 2025:"#BAB5D3"}

def load_hourly(y):
    df = pd.read_csv(paths[y])
    df["year"] = y
    return df

all_df = pd.concat([load_hourly(y) for y in [2023, 2024, 2025]], ignore_index=True)

for wtype, title in [("weekday","Ï£ºÏ§ë"), ("weekend","Ï£ºÎßê")]:
    d = all_df[all_df["weekday_type"] == wtype].copy()

    fig, ax = plt.subplots(figsize=(13.5, 7.0), dpi=200)
    ax.grid(alpha=0.25)
    for y in [2023, 2024, 2025]:
        sub = d[d["year"] == y].sort_values("hour")
        metric = "RentCnt" if "RentCnt" in sub.columns else "Volume"
        ax.plot(sub["hour"], sub[metric], marker="o", linewidth=3, label=str(y), color=YEAR_COLOR[y])
    ax.set_xticks(range(0,24))
    ax.set_xlabel("Hour")
    ax.set_ylabel(metric)
    ax.set_title(f"{title} ÏãúÍ∞ÑÎåÄÎ≥Ñ ÎåÄÏó¨ Î∂ÑÌè¨")
    ax.legend(loc="upper right", frameon=True)
    plt.tight_layout()
    plt.show()

    fig, ax = plt.subplots(figsize=(13.5, 7.0), dpi=200)
    ax.grid(alpha=0.25)
    for y in [2023, 2024, 2025]:
        sub = d[d["year"] == y].sort_values("hour")
        ax.plot(sub["hour"], sub["Net"], marker="o", linewidth=3, label=str(y), color=YEAR_COLOR[y])
    ax.set_xticks(range(0,24))
    ax.set_xlabel("Hour")
    ax.set_ylabel("Net (RtnCnt - RentCnt)")
    ax.set_title(f"{title} ÏãúÍ∞ÑÎåÄÎ≥Ñ Net Î∂ÑÌè¨")
    ax.legend(loc="upper right", frameon=True)
    plt.tight_layout()
    plt.show()


# In[ ]:


import os
import pandas as pd
import matplotlib.pyplot as plt

BASE_DIR = r"C:\Users\Ïù¥Ïú§ÏÑú\Documents\YONSEI\DSL\26-1\output"
paths = {
    2023: os.path.join(BASE_DIR, "hourly_by_weekday_2023.csv"),
    2024: os.path.join(BASE_DIR, "hourly_by_weekday_2024.csv"),
    2025: os.path.join(BASE_DIR, "hourly_by_weekday_2025.csv"),
}

weekday_order = ["Mon(Ïõî)","Tue(Ìôî)","Wed(Ïàò)","Thu(Î™©)","Fri(Í∏à)","Sat(ÌÜ†)","Sun(Ïùº)"]

for y in [2023, 2024, 2025]:
    df = pd.read_csv(paths[y])
    df["weekday_name"] = pd.Categorical(df["weekday_name"], categories=weekday_order, ordered=True)
    pivot = df.pivot_table(index="weekday_name", columns="hour", values="Net", aggfunc="mean").reindex(weekday_order)

    fig, ax = plt.subplots(figsize=(15, 4.5), dpi=220)
    im = ax.imshow(pivot.values, aspect="auto")
    ax.set_title(f"{y} ÏöîÏùº√óÏãúÍ∞ÑÎåÄ Net ÌûàÌä∏Îßµ")
    ax.set_yticks(range(len(pivot.index)))
    ax.set_yticklabels(pivot.index.tolist())
    ax.set_xticks(range(0,24))
    ax.set_xticklabels(list(range(0,24)))
    plt.colorbar(im, ax=ax, fraction=0.025, pad=0.02)
    plt.tight_layout()
    plt.show()


# In[ ]:


import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

BASE_DIR = r"C:\Users\Ïù¥Ïú§ÏÑú\Documents\YONSEI\DSL\26-1\output"
p = os.path.join(BASE_DIR, "hourly_profile_2025.csv")
df = pd.read_csv(p)

d = df[df["weekday_type"] == "weekday"].sort_values("hour").copy()
y = d["RentCnt"].to_numpy()
hours = d["hour"].to_numpy()

def piecewise_mean_pred(hours, y, am=(5,7), pm=(16,19)):
    pred = np.zeros_like(y, dtype=float)
    am_mask = (hours >= am[0]) & (hours <= am[1])
    pm_mask = (hours >= pm[0]) & (hours <= pm[1])
    np_mask = ~(am_mask | pm_mask)
    pred[am_mask] = y[am_mask].mean() if am_mask.any() else 0
    pred[pm_mask] = y[pm_mask].mean() if pm_mask.any() else 0
    pred[np_mask] = y[np_mask].mean() if np_mask.any() else 0
    return pred

am = (5,7)
pm = (16,19)
pred = piecewise_mean_pred(hours, y, am=am, pm=pm)

fig, ax = plt.subplots(figsize=(13.5, 6.5), dpi=220)
ax.plot(hours, y, marker="o", linewidth=3, label="Hourly Mean Rentals")
ax.plot(hours, pred, linewidth=3, label="3-Block Mean (AM/PM/Non-Peak)")
ax.axvspan(am[0]-0.5, am[1]+0.5, alpha=0.12)
ax.axvspan(pm[0]-0.5, pm[1]+0.5, alpha=0.12)
ax.set_xticks(range(0,24))
ax.set_xlabel("Hour")
ax.set_ylabel("RentCnt")
ax.legend(frameon=True)
plt.tight_layout()
plt.show()


# In[ ]:


import os, re, zipfile
import numpy as np
import pandas as pd

BASE_DIR = r"C:\Users\Ïù¥Ïú§ÏÑú\Documents\YONSEI\DSL\26-1"

AM_RANGE = (5, 7)
PM_RANGE = (16, 19)

HOLIDAYS = {
    2023: pd.to_datetime([
        "2023-01-01","2023-01-21","2023-01-22","2023-01-23","2023-01-24",
        "2023-03-01","2023-05-05","2023-05-27","2023-05-29","2023-06-06",
        "2023-08-15","2023-09-28","2023-09-29","2023-09-30","2023-10-02",
        "2023-10-03","2023-10-09","2023-12-25",
    ]),
    2024: pd.to_datetime([
        "2024-01-01","2024-02-09","2024-02-10","2024-02-11","2024-02-12",
        "2024-03-01","2024-04-10","2024-05-05","2024-05-06","2024-05-15",
        "2024-06-06","2024-08-15","2024-09-16","2024-09-17","2024-09-18",
        "2024-10-03","2024-10-09","2024-12-25",
    ]),
    2025: pd.to_datetime([
        "2025-01-01","2025-01-28","2025-01-29","2025-01-30",
        "2025-03-01","2025-03-03","2025-05-05","2025-05-06",
        "2025-06-06","2025-08-15","2025-10-03","2025-10-06","2025-10-07",
        "2025-10-08","2025-10-09","2025-12-25",
    ])
}

def make_hour_from_timecol(s: pd.Series) -> pd.Series:
    t = pd.to_numeric(s, errors="coerce")
    mx = t.max(skipna=True)
    if pd.isna(mx):
        ss = s.astype(str).str.extract(r"(\d{1,2})", expand=False)
        return pd.to_numeric(ss, errors="coerce")
    mx = float(mx)
    if mx <= 23:
        return t.astype("Int64")
    if mx <= 2359:
        return (t.astype("Int64") // 100)
    if mx <= 1440:
        return (t.astype("Int64") // 60)
    if mx <= 300:
        minutes = t.astype("Int64") * 5
        return (minutes // 60)
    return (t.astype("Int64") % 24)

def assign_time_block(hour_series: pd.Series) -> pd.Series:
    return np.select(
        [hour_series.between(*AM_RANGE), hour_series.between(*PM_RANGE)],
        ["Peak_Morning", "Peak_Evening"],
        default="Non_Peak"
    )

def read_csv_flexible(raw: bytes) -> pd.DataFrame:
    try:
        d = pd.read_csv(pd.io.common.BytesIO(raw), encoding="cp949", sep=None, engine="python", low_memory=False)
    except:
        d = pd.read_csv(pd.io.common.BytesIO(raw), encoding="cp949", sep="\t", engine="python", low_memory=False)

    cols = {c.strip(): c for c in d.columns}
    keymap = {}
    for k in ["Í∏∞Ï§Ä_ÏãúÍ∞ÑÎåÄ","Í∏∞Ï§Ä_ÏãúÍ∞Ñ"]:
        if k in cols:
            keymap["Í∏∞Ï§Ä_ÏãúÍ∞ÑÎåÄ"] = cols[k]
            break

    for k in ["Í∏∞Ï§Ä_ÎÇ†Ïßú","Í∏∞Ï§ÄÏùºID","Í∏∞Ï§ÄÏùº"]:
        if k in cols:
            keymap["Í∏∞Ï§Ä_ÎÇ†Ïßú"] = cols[k]
            break

    for k in ["ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID","ÎåÄÏó¨ÏÜåÎ≤àÌò∏","ÎåÄÏó¨ÏÜå_ID"]:
        if k in cols:
            keymap["ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID"] = cols[k]
            break

    for k in ["Ï†ÑÏ≤¥_Í±¥Ïàò","ÎåÄÏó¨Í±¥Ïàò","Í±¥Ïàò"]:
        if k in cols:
            keymap["Ï†ÑÏ≤¥_Í±¥Ïàò"] = cols[k]
            break

    if not all(k in keymap for k in ["Í∏∞Ï§Ä_ÏãúÍ∞ÑÎåÄ","ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID","Ï†ÑÏ≤¥_Í±¥Ïàò"]):
        raise ValueError("required columns not found")

    out = pd.DataFrame({
        "Í∏∞Ï§Ä_ÏãúÍ∞ÑÎåÄ": d[keymap["Í∏∞Ï§Ä_ÏãúÍ∞ÑÎåÄ"]],
        "ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID": d[keymap["ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID"]],
        "Ï†ÑÏ≤¥_Í±¥Ïàò": d[keymap["Ï†ÑÏ≤¥_Í±¥Ïàò"]],
    })
    return out

def add_weekend_holiday_flags(df: pd.DataFrame, year: int) -> pd.DataFrame:
    s = df["Í∏∞Ï§ÄÏùºID"].astype(str)
    dt = pd.to_datetime(s, format="%Y%m%d", errors="coerce")
    df["is_weekend"] = dt.dt.dayofweek.ge(5).astype(int)
    holiday_set = set(HOLIDAYS[year].date)
    df["is_holiday"] = dt.dt.date.isin(holiday_set).astype(int)
    return df

def build_station_day_timeblock_avg(year: int):
    out_csv = os.path.join(BASE_DIR, f"station_day_timeblock_avg_{year}.csv")
    zip_files = sorted(glob.glob(os.path.join(BASE_DIR, f"tpss_bcycl_od_statnhm_{year}*.zip")))
    if not zip_files:
        raise FileNotFoundError(f"zip not found for year={year}")

    all_g = []
    skipped = 0

    for zpath in zip_files:
        with zipfile.ZipFile(zpath) as z:
            csv_names = [n for n in z.namelist() if n.lower().endswith(".csv")]
            for name in csv_names:
                m = re.search(r"(\d{8})", name)
                if m is None:
                    continue
                day = m.group(1)
                raw = z.read(name)
                try:
                    d = read_csv_flexible(raw)
                except:
                    skipped += 1
                    continue

                d["Í∏∞Ï§ÄÏùºID"] = day
                d["hour"] = make_hour_from_timecol(d["Í∏∞Ï§Ä_ÏãúÍ∞ÑÎåÄ"]).astype("Int64")
                d = d.dropna(subset=["Í∏∞Ï§ÄÏùºID","hour","ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID"])
                if d.empty:
                    continue
                d["hour"] = d["hour"].astype("int8")

                h = (d.groupby(["Í∏∞Ï§ÄÏùºID","ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID","hour"], observed=True)["Ï†ÑÏ≤¥_Í±¥Ïàò"]
                       .sum()
                       .reset_index(name="hourly_rentals"))
                h["TIME_BLOCK"] = assign_time_block(h["hour"])

                g = (h.groupby(["Í∏∞Ï§ÄÏùºID","ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID","TIME_BLOCK"], observed=True)["hourly_rentals"]
                       .mean()
                       .reset_index(name="rentals(Y)"))

                all_g.append(g)

    final_df = pd.concat(all_g, ignore_index=True).rename(columns={"ÏãúÏûë_ÎåÄÏó¨ÏÜå_ID":"ÎåÄÏó¨ÏÜåÎ≤àÌò∏"})
    final_df["Í∏∞Ï§ÄÏùºID"] = final_df["Í∏∞Ï§ÄÏùºID"].astype(int)
    final_df = add_weekend_holiday_flags(final_df, year)
    final_df = final_df[["Í∏∞Ï§ÄÏùºID","ÎåÄÏó¨ÏÜåÎ≤àÌò∏","TIME_BLOCK","rentals(Y)","is_weekend","is_holiday"]]
    final_df.to_csv(out_csv, index=False, encoding="utf-8-sig")
    print(f"[OK] {year} -> {out_csv} | rows={len(final_df):,} | skipped_files={skipped}")
    return out_csv

import glob
for y in [2023, 2024, 2025]:
    build_station_day_timeblock_avg(y)

"""## ÌñâÏ†ïÍµ¨Ïó≠"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import glob

# ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÑ§Ï†ï (Windows Í∏∞Ï§Ä)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# 1. Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞ (ÌååÏùºÎ™ÖÏùÄ Î≥∏Ïù∏Ïùò ÌååÏùºÎ™ÖÏúºÎ°ú ÏàòÏ†ï)
df = pd.read_csv('ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í≥µÍ≥µÏûêÏ†ÑÍ±∞ ÎåÄÏó¨ÏÜåÎ≥Ñ Ïù¥Ïö©Ï†ïÎ≥¥(ÏõîÎ≥Ñ)_25.1-6.csv', encoding='cp949')

# 2. Ï†ÑÏ≤òÎ¶¨: 'Í∏∞Ï§ÄÎÖÑÏõî'ÏùÑ Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò (ÏãúÍ∞ÅÌôî Ïãú Ïà´Ïûê Í≥ÑÏÇ∞ Î∞©ÏßÄ)
df['Í∏∞Ï§ÄÎÖÑÏõî'] = df['Í∏∞Ï§ÄÎÖÑÏõî'].astype(str)

# 3. ÌñâÏ†ïÍµ¨(ÏûêÏπòÍµ¨)Î≥Ñ Îç∞Ïù¥ÌÑ∞ ÏßëÍ≥Ñ
# Í∞Å Íµ¨Î≥ÑÎ°ú ÎåÄÏó¨Í±¥ÏàòÏôÄ Î∞òÎÇ©Í±¥ÏàòÏùò Ìï©Í≥ÑÎ•º Íµ¨Ìï©ÎãàÎã§.
district_usage = df.groupby('ÏûêÏπòÍµ¨')[['ÎåÄÏó¨Í±¥Ïàò', 'Î∞òÎÇ©Í±¥Ïàò']].sum().reset_index()

# 4. ÏãúÍ∞ÅÌôî: ÏûêÏπòÍµ¨Î≥Ñ ÎåÄÏó¨Í±¥Ïàò ÎßâÎåÄ Í∑∏ÎûòÌîÑ
plt.figure(figsize=(12, 6))
sns.barplot(data=district_usage.sort_values('ÎåÄÏó¨Í±¥Ïàò', ascending=False),
            x='ÏûêÏπòÍµ¨', y='ÎåÄÏó¨Í±¥Ïàò', palette='viridis')
plt.title('ÏÑúÏö∏Ïãú ÏûêÏπòÍµ¨Î≥Ñ Îî∞Î¶âÏù¥ ÎåÄÏó¨Í±¥Ïàò (2025ÎÖÑ 01Ïõî)')
plt.xticks(rotation=45)
plt.show()

# 3. 1ÎÖÑÏπò Îç∞Ïù¥ÌÑ∞ ÏûêÏπòÍµ¨Î≥ÑÎ°ú Ìï©ÏÇ∞ÌïòÍ∏∞
# 'ÏûêÏπòÍµ¨'Î°ú Í∑∏Î£πÌôîÌïòÏó¨ 'ÎåÄÏó¨Í±¥Ïàò'Ïùò Ï¥ùÌï©ÏùÑ Íµ¨Ìï©ÎãàÎã§.
district_yearly_total = df.groupby('ÏûêÏπòÍµ¨')['ÎåÄÏó¨Í±¥Ïàò'].sum().reset_index()

# 4. ÏãúÍ∞ÅÌôî: ÏûêÏπòÍµ¨Î≥Ñ Ï¥ù ÎåÄÏó¨Í±¥Ïàò ÎßâÎåÄ Í∑∏ÎûòÌîÑ (ÎÇ¥Î¶ºÏ∞®Ïàú Ï†ïÎ†¨)
plt.figure(figsize=(15, 8))
sns.barplot(
    data=district_yearly_total.sort_values('ÎåÄÏó¨Í±¥Ïàò', ascending=False),
    x='ÏûêÏπòÍµ¨',
    y='ÎåÄÏó¨Í±¥Ïàò',
    palette='magma'  # ÏÉâÏÉÅ ÌÖåÎßà Î≥ÄÍ≤Ω
)

# Í∑∏ÎûòÌîÑ Ï†ïÎ≥¥ Ï∂îÍ∞Ä
plt.title('2025ÎÖÑ ÏÑúÏö∏Ïãú ÏûêÏπòÍµ¨Î≥Ñ Îî∞Î¶âÏù¥ Ï¥ù ÎåÄÏó¨Í±¥Ïàò (1Ïõî~12Ïõî Ìï©Í≥Ñ)', fontsize=16, pad=20)
plt.xlabel('ÏûêÏπòÍµ¨Î™Ö', fontsize=12)
plt.ylabel('Ï¥ù ÎåÄÏó¨Í±¥Ïàò (Ï≤úÎßå Îã®ÏúÑ)', fontsize=12)
plt.xticks(rotation=45) # Íµ¨ Ïù¥Î¶ÑÏù¥ Í≤πÏπòÏßÄ ÏïäÍ≤å ÌöåÏ†Ñ

# Í∑∏ÎûòÌîÑ Ï∂úÎ†•
plt.tight_layout()
plt.show()

# 2023~2025ÎÖÑ 3Í∞úÎÖÑ Îç∞Ïù¥ÌÑ∞ Ìï©Ï≥êÏÑú ÏûêÏπòÍµ¨Î≥Ñ Ï¥ù ÎåÄÏó¨Í±¥Ïàò (Î™®Îì† Ïõî Ìï©Í≥Ñ) ÏãúÍ∞ÅÌôî
file_list_3y = [
    'ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í≥µÍ≥µÏûêÏ†ÑÍ±∞ ÎåÄÏó¨ÏÜåÎ≥Ñ Ïù¥Ïö©Ï†ïÎ≥¥(ÏõîÎ≥Ñ)_23.1-6.csv',
    'ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í≥µÍ≥µÏûêÏ†ÑÍ±∞ ÎåÄÏó¨ÏÜåÎ≥Ñ Ïù¥Ïö©Ï†ïÎ≥¥(ÏõîÎ≥Ñ)_23.7-12.csv',
    'ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í≥µÍ≥µÏûêÏ†ÑÍ±∞ ÎåÄÏó¨ÏÜåÎ≥Ñ Ïù¥Ïö©Ï†ïÎ≥¥(ÏõîÎ≥Ñ)_24.1-6.csv',
    'ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í≥µÍ≥µÏûêÏ†ÑÍ±∞ ÎåÄÏó¨ÏÜåÎ≥Ñ Ïù¥Ïö©Ï†ïÎ≥¥(ÏõîÎ≥Ñ)_24.7-12.csv',
    'ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í≥µÍ≥µÏûêÏ†ÑÍ±∞ ÎåÄÏó¨ÏÜåÎ≥Ñ Ïù¥Ïö©Ï†ïÎ≥¥(ÏõîÎ≥Ñ)_25.1-6.csv',
    'ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í≥µÍ≥µÏûêÏ†ÑÍ±∞ ÎåÄÏó¨ÏÜåÎ≥Ñ Ïù¥Ïö©Ï†ïÎ≥¥(ÏõîÎ≥Ñ)_25.7-12.csv'
]
df_3y = pd.concat([pd.read_csv(f, encoding='cp949') for f in file_list_3y], ignore_index=True)

# ÎåÄÏó¨Í±¥ÏàòÎ•º Ïà´ÏûêÌòïÏúºÎ°ú Î≥ÄÌôò (Î¨∏ÏûêÏó¥Ïù¥ ÏÑûÏó¨ ÏûàÏúºÎ©¥ sum Ïãú ÏóêÎü¨ Î∞©ÏßÄ)
df_3y['ÎåÄÏó¨Í±¥Ïàò'] = pd.to_numeric(df_3y['ÎåÄÏó¨Í±¥Ïàò'], errors='coerce').fillna(0).astype(int)

# ÏûêÏπòÍµ¨Î≥Ñ ÎåÄÏó¨Í±¥Ïàò Ìï©Í≥Ñ (3Í∞úÎÖÑ Ï†ÑÏ≤¥ Ïõî Ìï©ÏÇ∞)
district_3y_total = df_3y.groupby('ÏûêÏπòÍµ¨')['ÎåÄÏó¨Í±¥Ïàò'].sum().reset_index()

# ÎåÄÏó¨Í±¥Ïàò ÎÇ¥Î¶ºÏ∞®Ïàú Ï†ïÎ†¨
district_3y_total = district_3y_total.sort_values('ÎåÄÏó¨Í±¥Ïàò', ascending=False)

# ÏãúÍ∞ÅÌôî
plt.figure(figsize=(15, 8))
sns.barplot(
    data=district_3y_total,
    x='ÏûêÏπòÍµ¨',
    y='ÎåÄÏó¨Í±¥Ïàò',
    hue='ÏûêÏπòÍµ¨',
    legend=False,
    palette='magma'
)
plt.title('2023~2025ÎÖÑ ÏÑúÏö∏Ïãú ÏûêÏπòÍµ¨Î≥Ñ Îî∞Î¶âÏù¥ Ï¥ù ÎåÄÏó¨Í±¥Ïàò (3Í∞úÎÖÑ Ï†ÑÏ≤¥ Ïõî Ìï©Í≥Ñ)', fontsize=16, pad=20)
plt.xlabel('ÏûêÏπòÍµ¨Î™Ö', fontsize=12)
plt.ylabel('Ï¥ù ÎåÄÏó¨Í±¥Ïàò', fontsize=12)
plt.xticks(rotation=45)
plt.tight_layout()

# 5. ÏãúÍ∞ÅÌôî: ÏõîÎ≥Ñ Ï∂îÏù¥ (Îç∞Ïù¥ÌÑ∞Ïóê Ïó¨Îü¨ Îã¨Ïù¥ ÏÑûÏó¨ ÏûàÏùÑ Í≤ΩÏö∞)
monthly_usage = df.groupby(['Í∏∞Ï§ÄÎÖÑÏõî', 'ÏûêÏπòÍµ¨'])['ÎåÄÏó¨Í±¥Ïàò'].sum().reset_index()
plt.figure(figsize=(14, 7))
sns.lineplot(data=monthly_usage, x='Í∏∞Ï§ÄÎÖÑÏõî', y='ÎåÄÏó¨Í±¥Ïàò', hue='ÏûêÏπòÍµ¨', marker='o')
plt.title('ÏûêÏπòÍµ¨Î≥Ñ ÏõîÎ≥Ñ Îî∞Î¶âÏù¥ Ïù¥Ïö© Ï∂îÏù¥')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""## Ïó∞Î†π"""

import pandas as pd
import os

path = 'C:/Users/User/Desktop/EDA'
csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]

df_list = []

for file in csv_files:
    temp_df = pd.read_csv(os.path.join(path, file), encoding='cp949')
    df_list.append(temp_df)

total_df = pd.concat(df_list, ignore_index=True)

total_df.to_csv('C:/Users/User/Desktop/EDA/total_bicycle_2.csv', index=False)

import pandas as pd
csv_path = r"C:/Users/User/Desktop/EDA/total_bicycle_2.csv"
print(pd.read_csv(csv_path, nrows=0).columns.tolist())

import pyarrow.csv as pv
import pyarrow.parquet as pq
from pathlib import Path

csv_path = Path(r"C:/Users/User/Desktop/EDA/total_bicycle_2.csv")
parquet_path = csv_path.with_suffix(".parquet")

cols = ["ÎåÄÏó¨ÏùºÏûê", "ÎåÄÏó¨ÏÜåÎ≤àÌò∏", "ÎåÄÏó¨ÏÜåÎ™Ö", "Ïó∞Î†πÎåÄÏΩîÎìú", "Ïù¥ÎèôÍ±∞Î¶¨(M)", "Ïù¥Ïö©ÏãúÍ∞Ñ(Î∂Ñ)"]

table = pv.read_csv(
    csv_path.as_posix(),
    convert_options=pv.ConvertOptions(include_columns=cols),
    read_options=pv.ReadOptions(use_threads=True)
)

pq.write_table(table, parquet_path.as_posix())

import pandas as pd

df = pd.read_parquet(r"C:/Users/User/Desktop/EDA/total_bicycle_2.parquet")
df.columns

df = df.rename(columns={
    'ÎåÄÏó¨ÏùºÏûê' : 'date',
    'ÎåÄÏó¨ÏÜåÎ≤àÌò∏': 'station_id',
    'ÎåÄÏó¨ÏÜåÎ™Ö' : 'station_name',
    'Ïó∞Î†πÎåÄÏΩîÎìú': 'age_group',
    'Ïù¥ÎèôÍ±∞Î¶¨(M)': 'distance_m',
    'Ïù¥Ïö©ÏãúÍ∞Ñ(Î∂Ñ)': 'duration_min'
})

df.columns

def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    return df[(df[column] >= lower) & (df[column] <= upper)]

df_clean = remove_outliers(df, 'duration_min')
df_f = df_clean[df_clean['age_group'] != 'Í∏∞ÌÉÄ']

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

C_DARK  = "#260A6E"
C_MID   = "#7D6CA8"
C_LIGHT = "#BDB5D3"

sns.set_theme(style="whitegrid")
plt.rcParams.update({
    "axes.titlesize": 14,
    "axes.titleweight": "bold",
    "axes.labelsize": 11,
    "ytick.labelsize": 10
})

fig, ax = plt.subplots(figsize=(5.5, 4))

sns.boxplot(
    y=df_f['duration_min'],
    width=0.45,
    showfliers=False,
    boxprops=dict(
        facecolor=C_LIGHT,
        edgecolor=C_DARK,
        linewidth=1.6
    ),
    whiskerprops=dict(color=C_DARK, linewidth=1.4),
    capprops=dict(color=C_DARK, linewidth=1.4),
    medianprops=dict(color=C_DARK, linewidth=2.4),
    ax=ax
)

ax.set_ylabel("Duration (min)")
ax.set_xlabel("")
ax.set_title("Distribution of Trip Duration")


ax.grid(axis='y', linestyle='--', alpha=0.35)
ax.grid(axis='x', visible=False)


ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['left'].set_color("#333333")
ax.spines['bottom'].set_color("#333333")

median = np.median(df_f['duration_min'])
ax.text(
    0, median,
    f"  median {median:.1f}",
    va="center",
    ha="left",
    color=C_DARK,
    fontsize=10,
    fontweight="bold"
)

plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

def age_grouping(age_group):
    if age_group in ['~10ÎåÄ', '20ÎåÄ', '30ÎåÄ', '40ÎåÄ']:
        return 'YOUNG'
    elif age_group in ['50ÎåÄ', '60ÎåÄ', '70ÎåÄÏù¥ÏÉÅ']:
        return 'OLD'
    else:
        return None

df_f['age_cluster'] = df_f['age_group'].apply(age_grouping)
df_cluster = df_f[df_f['age_cluster'].notna()]

sns.boxplot(
    data=df_cluster,
    x='age_cluster',
    y='duration_min',
    showfliers=False
)

plt.xlabel('Age group')
plt.ylabel('Duration(min)')
plt.title('Duration per age')
plt.show()

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


C_DARK = "#260A6E"
C_MID  = "#7D6CA8"
C_LIGHT= "#BDB5D3"


def age_grouping(age_group):
    if age_group in ['~10ÎåÄ', '20ÎåÄ', '30ÎåÄ', '40ÎåÄ']:
        return 'YOUNG'
    elif age_group in ['50ÎåÄ', '60ÎåÄ', '70ÎåÄÏù¥ÏÉÅ']:
        return 'OLD'
    else:
        return None

df_f['age_cluster'] = df_f['age_group'].apply(age_grouping)
df_cluster = df_f[df_f['age_cluster'].notna()].copy()

order = ['YOUNG', 'OLD']

sns.set_theme(style="whitegrid")
plt.rcParams.update({
    "axes.titlesize": 14,
    "axes.titleweight": "bold",
    "axes.labelsize": 11,
    "xtick.labelsize": 10,
    "ytick.labelsize": 10
})

fig, ax = plt.subplots(figsize=(7, 4.2))

sns.boxplot(
    data=df_cluster,
    x='age_cluster',
    y='duration_min',
    order=order,
    width=0.45,
    showfliers=False,
    palette=[C_MID, C_LIGHT],
    saturation=1,
    boxprops=dict(edgecolor=C_DARK, linewidth=1.6),
    whiskerprops=dict(color=C_DARK, linewidth=1.4),
    capprops=dict(color=C_DARK, linewidth=1.4),
    medianprops=dict(color=C_DARK, linewidth=2.2),
    ax=ax
)

ax.set_xlabel("Age cluster")
ax.set_ylabel("Duration (min)")
ax.set_title("Duration per age (YOUNG vs OLD)", pad=10)

ax.grid(axis='y', linestyle='--', linewidth=0.8, alpha=0.35)
ax.grid(axis='x', visible=False)


ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['left'].set_color("#333333")
ax.spines['bottom'].set_color("#333333")
ax.spines['left'].set_linewidth(1.0)
ax.spines['bottom'].set_linewidth(1.0)


group_stats = df_cluster.groupby('age_cluster')['duration_min'].agg(['median', 'count'])
ymax = df_cluster['duration_min'].max()

for i, g in enumerate(order):
    if g not in group_stats.index:
        continue
    med = group_stats.loc[g, 'median']
    n = int(group_stats.loc[g, 'count'])

    ax.text(
        i, med + 0.02*ymax,
        f"median {med:.1f}",
        ha="center", va="bottom",
        fontsize=10, color=C_DARK, fontweight="bold"


plt.tight_layout()
plt.show()

df_f = df_f[df_f['age_group'] != '']
bottom25_stations = (
    df_f['station_id']
    .value_counts()
    .tail(25)
    .index
)

df_bottom25 = df_f[df_f['station_id'].isin(bottom25_stations)]
station_age_count = (
    df_bottom25
    .groupby(['station_id', 'age_group'])
    .size()
    .reset_index(name='count')
)
pivot_count = (
    station_age_count
    .pivot(index='station_id', columns='age_group', values='count')
    .fillna(0)
)

pivot_count['total'] = pivot_count.sum(axis=1)

pivot_count = pivot_count.sort_values(
    by='total',
    ascending=False
)

pivot_count = pivot_count.drop(columns='total')

import matplotlib.pyplot as plt

ax = pivot_count.plot(
    kind='bar',
    stacked=True,
    figsize=(14, 6)
)

ax.set_title('Bottom 25 Stations by Total Usage (Age Composition)')
ax.set_xlabel('Station ID')
ax.set_ylabel('Total usage count')

plt.xticks(rotation=90)
plt.legend(
    title='Age group',
    bbox_to_anchor=(1.05, 1),
    loc='upper left'
)

plt.tight_layout()
plt.show()

"""## Ïù¥Ïö©Í∂å"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False


df = pd.read_csv('ÏÑúÏö∏ÌäπÎ≥ÑÏãú Í≥µÍ≥µÏûêÏ†ÑÍ±∞ Ïù¥Ïö©Ï†ïÎ≥¥(ÏãúÍ∞ÑÎåÄÎ≥Ñ).csv', encoding='cp949')


df['ÎåÄÏó¨ÏùºÏûê'] = pd.to_datetime(df['ÎåÄÏó¨ÏùºÏûê'])
df['ÎåÄÏó¨ÏÜåÎ≤àÌò∏'] = pd.to_numeric(df['ÎåÄÏó¨ÏÜåÎ≤àÌò∏'], errors='coerce')
df = df.dropna(subset=['ÎåÄÏó¨ÏÜåÎ≤àÌò∏'])


ticket_usage = df.groupby('Ïù¥Ïö©Í∂åÍµ¨Î∂Ñ').agg({
    'Ïù¥Ïö©Í±¥Ïàò': 'sum',
    'Ïù¥Ïö©ÏãúÍ∞Ñ(Î∂Ñ)': 'mean',
    'Ïù¥Ïö©Í±∞Î¶¨(m)': 'mean'
}).reset_index()


plt.figure(figsize=(10, 6))
sns.barplot(data=ticket_usage, x='Ïù¥Ïö©Í∂åÍµ¨Î∂Ñ', y='Ïù¥Ïö©Í±¥Ïàò', palette='pastel')
plt.title('Ïù¥Ïö©Í∂å Ï¢ÖÎ•òÎ≥Ñ Ï¥ù Ïù¥Ïö© Í±¥Ïàò ÎπÑÍµê')
plt.show()


station_stats = df.groupby('ÎåÄÏó¨ÏÜåÎ≤àÌò∏').agg({
    'Ïù¥Ïö©Í±¥Ïàò': 'sum',
    'Ïù¥Ïö©ÏãúÍ∞Ñ(Î∂Ñ)': 'sum',
    'Ïù¥Ïö©Í±∞Î¶¨(m)': 'sum'
}).reset_index()

print("Ïù¥Ïö©Í∂å Î∞è ÎåÄÏó¨ÏÜå ÏÑ±Í≥º Î∂ÑÏÑù ÏôÑÎ£å")
display(ticket_usage)

"""## Îã§Ï§ë ÏÑ†Ìòï ÌöåÍ∑Ä"""

import pandas as pd
import os

base_path = "/content/drive/MyDrive/DSL/26-1 EDA/ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞/Îã§Ï§ëÏÑ†ÌòïÌöåÍ∑Ä"
pop_path = "/content/drive/MyDrive/DSL/26-1 EDA/seoul_living_pop_2025_final.csv"

df_pop = pd.read_csv(pop_path)
df_weather = pd.read_csv(os.path.join(base_path, "ÎÇ†Ïî®.csv"), encoding='utf-8-sig')
df_dist = pd.read_csv(os.path.join(base_path, "ÏßÄÌïòÏ≤†Ïó≠ Í±∞Î¶¨.csv"), encoding='utf-8-sig')

weather_time_map = {'Ï∂úÍ∑º': 'Peak_Morning', 'Ìá¥Í∑º': 'Peak_Evening', 'Í∏∞Ï§ÄÏãúÍ∞Ñ': 'Non_Peak'}
df_weather['TIME_BLOCK'] = df_weather['ÏãúÍ∞ÑÎåÄ'].map(weather_time_map)

df_pop['Í∏∞Ï§ÄÏùºID'] = df_pop['Í∏∞Ï§ÄÏùºID'].astype(str)
df_weather['Í∏∞Ï§ÄÏùºID'] = pd.to_datetime(df_weather['ÎÇ†Ïßú']).dt.strftime('%Y%m%d')

master = pd.merge(
    df_pop,
    df_weather[['Í∏∞Ï§ÄÏùºID', 'TIME_BLOCK', 'Í∏∞Ïò®_ÌèâÍ∑†(¬∞C)', 'ÌíçÏÜç_ÌèâÍ∑†(m/s)', 'Í∞ïÏàòÏó¨Î∂Ä(0/1)', 'ÏÑúÏö∏_ÌèâÍ∑†_ÎØ∏ÏÑ∏Î®ºÏßÄ']],
    on=['Í∏∞Ï§ÄÏùºID', 'TIME_BLOCK'],
    how='inner'
)

final_df = pd.merge(master, df_dist, on='ÏûêÏπòÍµ¨', how='inner')

print(f"‚úÖ ÌÜµÌï© ÏôÑÎ£å! ÏµúÏ¢Ö Îç∞Ïù¥ÌÑ∞ ÏÖ∞Ïù¥ÌîÑ: {final_df.shape}")
output_file = "/content/drive/MyDrive/DSL/26-1 EDA/ttareungi_regression_master.csv"
final_df.to_csv(output_file, index=False, encoding='utf-8-sig')

display(final_df.head())

import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.preprocessing import StandardScaler
import os

path = "/content/drive/MyDrive/DSL/26-1 EDA/ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞/Îã§Ï§ëÏÑ†ÌòïÌöåÍ∑Ä/"
df_total = pd.read_csv(os.path.join(path, "integrated_ttareungi_data.csv"))

df_25 = df_total[df_total['year'] == 2025].copy()

df_25 = df_25.dropna(subset=['rentals(Y)', 'temp', 'Ï¥ùÏÉùÌôúÏù∏Íµ¨', 'ÏßÄÌïòÏ≤†Ïó≠Í±∞Î¶¨(m)'])

df_25['log_rentals'] = np.log1p(df_25['rentals(Y)'])
temp_mean = df_25['temp'].mean()
df_25['Í∏∞Ïò®_Ï§ëÏã¨Ìôî'] = df_25['temp'] - temp_mean
df_25['Í∏∞Ïò®_Ï§ëÏã¨Ìôî_Ï†úÍ≥±'] = df_25['Í∏∞Ïò®_Ï§ëÏã¨Ìôî'] ** 2

df_25 = df_25.rename(columns={
    'wind': 'ÌíçÏÜç_ÌèâÍ∑†(m/s)',
    'is_rain': 'Í∞ïÏàòÏó¨Î∂Ä(0/1)',
    'dust': 'ÏÑúÏö∏_ÌèâÍ∑†_ÎØ∏ÏÑ∏Î®ºÏßÄ'
})

scaler = StandardScaler()
df_25[['ÏßÄÌïòÏ≤†Ïó≠Í±∞Î¶¨(m)', 'Ï¥ùÏÉùÌôúÏù∏Íµ¨']] = scaler.fit_transform(df_25[['ÏßÄÌïòÏ≤†Ïó≠Í±∞Î¶¨(m)', 'Ï¥ùÏÉùÌôúÏù∏Íµ¨']])

df_25 = pd.get_dummies(df_25, columns=['ÏûêÏπòÍµ¨', 'TIME_BLOCK'], drop_first=True)

exclude = ['rentals(Y)', 'log_rentals', 'temp', 'rain_amt', 'year', 'Í∏∞Ï§ÄÏùºID', 'ÎåÄÏó¨ÏÜåÎ≤àÌò∏', 'ÎÇ†Ïßú', 'ÏãúÍ∞ÑÎåÄ']
X_cols = [c for c in df_25.columns if c not in exclude and not c.startswith('Unnamed')]

X_data = df_25[X_cols].astype(float)
X_data = sm.add_constant(X_data)
y = df_25['log_rentals']

model_25 = sm.OLS(y, X_data).fit()

print("\n" + "="*80)
print("üìä 2025ÎÖÑ ÏõêÎ≥∏ Í∏∞Î∞ò OLS Regression Results")
print("="*80)
print(model_25.summary())
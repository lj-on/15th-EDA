{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742c3ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# LithoBench 데이터 폴더 의미\n",
       "\n",
       "| 폴더명 | 의미(Meaning) | 공정 단계 | 설명 |\n",
       "|---|---|---|---|\n",
       "| target | 목표 패턴 | 입력 (Input) | 웨이퍼에 최종적으로 찍혀야 하는 이상적인 회로 도면입니다. (설계자 의도) |\n",
       "| pixelILT | 픽셀 기반 마스크 | 최적화 (Opt 1) | target을 구현하기 위해 픽셀 단위로 최적화된 마스크 패턴입니다. (모자이크 형태) |\n",
       "| levelsetILT | 곡선 기반 마스크 | 최적화 (Opt 2) | 레벨셋 알고리즘으로 생성된 부드러운 곡선(Curvilinear) 형태의 마스크입니다. (최신 공정 트렌드) |\n",
       "| litho | 광학 이미지 | 시뮬레이션 (Sim) | 마스크를 통과한 빛이 감광액에 도달했을 때의 에너지 분포(Aerial Image)입니다. |\n",
       "| resist | 감광액 패턴 | 결과 (Output) | litho 이미지에 임계값(Threshold)을 적용해 실제로 남게 된 패턴입니다. |\n",
       "| printed | 최종 식각 패턴 | 최종 결과 | 현상(Develop) 및 식각(Etching) 후의 최종 형상입니다. (resist와 거의 유사할 수 있음) |\n",
       "| gds / glp | 벡터/메타데이터 | 참조 (Ref) | 이미지의 원본 벡터 파일(gds)과 텍스트 파라미터(glp)입니다. |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "md = \"\"\"\n",
    "# LithoBench 데이터 폴더 의미\n",
    "\n",
    "| 폴더명 | 의미(Meaning) | 공정 단계 | 설명 |\n",
    "|---|---|---|---|\n",
    "| target | 목표 패턴 | 입력 (Input) | 웨이퍼에 최종적으로 찍혀야 하는 이상적인 회로 도면입니다. (설계자 의도) |\n",
    "| pixelILT | 픽셀 기반 마스크 | 최적화 (Opt 1) | target을 구현하기 위해 픽셀 단위로 최적화된 마스크 패턴입니다. (모자이크 형태) |\n",
    "| levelsetILT | 곡선 기반 마스크 | 최적화 (Opt 2) | 레벨셋 알고리즘으로 생성된 부드러운 곡선(Curvilinear) 형태의 마스크입니다. (최신 공정 트렌드) |\n",
    "| litho | 광학 이미지 | 시뮬레이션 (Sim) | 마스크를 통과한 빛이 감광액에 도달했을 때의 에너지 분포(Aerial Image)입니다. |\n",
    "| resist | 감광액 패턴 | 결과 (Output) | litho 이미지에 임계값(Threshold)을 적용해 실제로 남게 된 패턴입니다. |\n",
    "| printed | 최종 식각 패턴 | 최종 결과 | 현상(Develop) 및 식각(Etching) 후의 최종 형상입니다. (resist와 거의 유사할 수 있음) |\n",
    "| gds / glp | 벡터/메타데이터 | 참조 (Ref) | 이미지의 원본 벡터 파일(gds)과 텍스트 파라미터(glp)입니다. |\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(md))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b82c51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ViaSet\n",
      "- target: 116414 files\n",
      "- pixelILT: 116405 files\n",
      "- levelsetILT: 111958 files\n",
      "- litho: 116405 files\n",
      "- resist: 116405 files\n",
      "- printed: 116405 files\n",
      "- glp: 116414 files\n",
      "- gds: 0 files\n",
      "\n",
      "[Missing report]\n",
      "- missing in target: 10\n",
      "- missing in pixelILT: 19\n",
      "- missing in levelsetILT: 4466\n",
      "- missing in litho: 19\n",
      "- missing in resist: 19\n",
      "- missing in printed: 19\n",
      "- missing in glp: 10\n",
      "- missing in gds: 116424\n",
      "\n",
      "CSV 저장 완료: C:\\Users\\asap0\\OneDrive\\바탕 화면\\yonsei\\26-1 DSL\\eda\\SemiConductor_EDA_2602\\LithoBench\\0_Datasets\\lithodata\\ViaSet\\ViaSet_file_match_report.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# 데이터셋 루트\n",
    "root = Path(r\"C:\\Users\\asap0\\OneDrive\\바탕 화면\\yonsei\\26-1 DSL\\eda\\SemiConductor_EDA_2602\\LithoBench\\0_Datasets\\lithodata\")\n",
    "\n",
    "# 분석 대상 세트 선택 (예: \"ViaSet\", \"MetalSet\", \"StdContact\", \"StdContactTest\", \"StdMetal\")\n",
    "dataset_name = \"ViaSet\"\n",
    "\n",
    "dataset_dir = root / dataset_name\n",
    "if not dataset_dir.exists():\n",
    "    raise FileNotFoundError(dataset_dir)\n",
    "\n",
    "# 비교할 폴더들\n",
    "folders = [\"target\", \"pixelILT\", \"levelsetILT\", \"litho\", \"resist\", \"printed\", \"glp\", \"gds\"]\n",
    "\n",
    "# 각 폴더에서 stem(확장자 제외) 수집\n",
    "stems_by_folder = {}\n",
    "for f in folders:\n",
    "    d = dataset_dir / f\n",
    "    if not d.exists():\n",
    "        stems_by_folder[f] = set()\n",
    "        continue\n",
    "    stems_by_folder[f] = {p.stem for p in d.iterdir() if p.is_file()}\n",
    "\n",
    "# 전체 stem 집합\n",
    "all_stems = set().union(*stems_by_folder.values())\n",
    "\n",
    "# glp 간단 파싱: key=value 형태만 추출\n",
    "kv_re = re.compile(r\"^\\s*([A-Za-z0-9_\\-]+)\\s*=\\s*(.+)\\s*$\")\n",
    "\n",
    "def parse_glp(path: Path):\n",
    "    kv = {}\n",
    "    try:\n",
    "        with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                m = kv_re.match(line)\n",
    "                if m:\n",
    "                    kv[m.group(1)] = m.group(2)\n",
    "    except Exception:\n",
    "        return {}\n",
    "    return kv\n",
    "\n",
    "# CSV 저장용 rows\n",
    "rows = []\n",
    "\n",
    "for stem in sorted(all_stems):\n",
    "    row = {\"dataset\": dataset_name, \"stem\": stem}\n",
    "    for f in folders:\n",
    "        row[f\"has_{f}\"] = stem in stems_by_folder[f]\n",
    "\n",
    "    # glp 메타데이터 요약\n",
    "    glp_path = dataset_dir / \"glp\" / f\"{stem}.glp\"\n",
    "    if glp_path.exists():\n",
    "        kv = parse_glp(glp_path)\n",
    "        row[\"glp_keys\"] = \";\".join(sorted(kv.keys())[:10])\n",
    "        row[\"glp_kv_count\"] = len(kv)\n",
    "    else:\n",
    "        row[\"glp_keys\"] = \"\"\n",
    "        row[\"glp_kv_count\"] = 0\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# 요약 출력\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "for f in folders:\n",
    "    print(f\"- {f}: {len(stems_by_folder[f])} files\")\n",
    "\n",
    "# 누락 확인\n",
    "print(\"\\n[Missing report]\")\n",
    "for f in folders:\n",
    "    missing = [s for s in all_stems if s not in stems_by_folder[f]]\n",
    "    print(f\"- missing in {f}: {len(missing)}\")\n",
    "\n",
    "# CSV 저장\n",
    "out_csv = dataset_dir / f\"{dataset_name}_file_match_report.csv\"\n",
    "with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fieldnames = [\"dataset\", \"stem\"] + [f\"has_{f}\" for f in folders] + [\"glp_keys\", \"glp_kv_count\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"\\nCSV 저장 완료: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04bbe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200/2000\n",
      "Processed 400/2000\n",
      "Processed 600/2000\n",
      "Processed 800/2000\n",
      "Processed 1000/2000\n",
      "Processed 1200/2000\n",
      "Processed 1400/2000\n",
      "Processed 1600/2000\n",
      "Processed 1800/2000\n",
      "Processed 2000/2000\n",
      "\n",
      "CSV 저장 완료: C:\\Users\\asap0\\OneDrive\\바탕 화면\\yonsei\\26-1 DSL\\eda\\SemiConductor_EDA_2602\\LithoBench\\0_Datasets\\lithodata\\ViaSet\\ViaSet_pixel_compare.csv\n",
      "총 처리 파일 수: 2000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 데이터셋 루트 및 대상 세트\n",
    "root = Path(r\"C:\\Users\\asap0\\OneDrive\\바탕 화면\\yonsei\\26-1 DSL\\eda\\SemiConductor_EDA_2602\\LithoBench\\0_Datasets\\lithodata\")\n",
    "dataset_name = \"ViaSet\"\n",
    "dataset_dir = root / dataset_name\n",
    "\n",
    "# 비교할 이미지 폴더 쌍 (A vs B)\n",
    "compare_pairs = [\n",
    "    (\"target\", \"printed\"),\n",
    "    (\"target\", \"resist\"),\n",
    "    (\"target\", \"litho\"),\n",
    "]\n",
    "\n",
    "# 처리 속도 제어\n",
    "max_files = 2000  # None이면 전체 수행\n",
    "print_every = 200\n",
    "\n",
    "# glp 파싱 (key=value)\n",
    "kv_re = re.compile(r\"^\\s*([A-Za-z0-9_\\-]+)\\s*=\\s*(.+)\\s*$\")\n",
    "\n",
    "def parse_glp(path: Path):\n",
    "    kv = {}\n",
    "    try:\n",
    "        with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                m = kv_re.match(line)\n",
    "                if m:\n",
    "                    kv[m.group(1)] = m.group(2)\n",
    "    except Exception:\n",
    "        return {}\n",
    "    return kv\n",
    "\n",
    "# 이미지 로드 (그레이스케일)\n",
    "\n",
    "def load_gray(path: Path):\n",
    "    with Image.open(path) as img:\n",
    "        return np.array(img.convert(\"L\"), dtype=np.float32)\n",
    "\n",
    "# 지표 계산\n",
    "\n",
    "def mse(a, b):\n",
    "    return float(np.mean((a - b) ** 2))\n",
    "\n",
    "\n",
    "def mae(a, b):\n",
    "    return float(np.mean(np.abs(a - b)))\n",
    "\n",
    "\n",
    "def psnr(a, b):\n",
    "    m = mse(a, b)\n",
    "    if m == 0:\n",
    "        return float(\"inf\")\n",
    "    return float(20 * np.log10(255.0) - 10 * np.log10(m))\n",
    "\n",
    "\n",
    "# 파일 stem 기준으로 매칭: 비교쌍의 교집합만 사용\n",
    "folders = sorted({f for pair in compare_pairs for f in pair})\n",
    "stems_by_folder = {}\n",
    "for f in folders:\n",
    "    d = dataset_dir / f\n",
    "    stems_by_folder[f] = {p.stem for p in d.iterdir() if p.is_file()} if d.exists() else set()\n",
    "\n",
    "if stems_by_folder:\n",
    "    common_stems = set.intersection(*stems_by_folder.values())\n",
    "else:\n",
    "    common_stems = set()\n",
    "\n",
    "stems = sorted(common_stems)\n",
    "if max_files is not None:\n",
    "    stems = stems[:max_files]\n",
    "\n",
    "# CSV 저장 (스트리밍)\n",
    "out_csv = dataset_dir / f\"{dataset_name}_pixel_compare.csv\"\n",
    "fieldnames = [\"dataset\", \"stem\", \"glp_kv_count\", \"glp_keys\"]\n",
    "for a_name, b_name in compare_pairs:\n",
    "    key_prefix = f\"{a_name}_vs_{b_name}\"\n",
    "    fieldnames += [\n",
    "        f\"{key_prefix}_status\",\n",
    "        f\"{key_prefix}_mse\",\n",
    "        f\"{key_prefix}_mae\",\n",
    "        f\"{key_prefix}_psnr\",\n",
    "    ]\n",
    "\n",
    "with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for i, stem in enumerate(stems, start=1):\n",
    "        row = {\"dataset\": dataset_name, \"stem\": stem}\n",
    "\n",
    "        # glp 정보 요약\n",
    "        glp_path = dataset_dir / \"glp\" / f\"{stem}.glp\"\n",
    "        if glp_path.exists():\n",
    "            kv = parse_glp(glp_path)\n",
    "            row[\"glp_kv_count\"] = len(kv)\n",
    "            row[\"glp_keys\"] = \";\".join(sorted(kv.keys())[:10])\n",
    "        else:\n",
    "            row[\"glp_kv_count\"] = 0\n",
    "            row[\"glp_keys\"] = \"\"\n",
    "\n",
    "        # 이미지 비교\n",
    "        for a_name, b_name in compare_pairs:\n",
    "            a_path = dataset_dir / a_name / f\"{stem}.png\"\n",
    "            b_path = dataset_dir / b_name / f\"{stem}.png\"\n",
    "            key_prefix = f\"{a_name}_vs_{b_name}\"\n",
    "            if a_path.exists() and b_path.exists():\n",
    "                a = load_gray(a_path)\n",
    "                b = load_gray(b_path)\n",
    "                if a.shape != b.shape:\n",
    "                    row[f\"{key_prefix}_status\"] = \"shape_mismatch\"\n",
    "                    row[f\"{key_prefix}_mse\"] = \"\"\n",
    "                    row[f\"{key_prefix}_mae\"] = \"\"\n",
    "                    row[f\"{key_prefix}_psnr\"] = \"\"\n",
    "                else:\n",
    "                    row[f\"{key_prefix}_status\"] = \"ok\"\n",
    "                    row[f\"{key_prefix}_mse\"] = mse(a, b)\n",
    "                    row[f\"{key_prefix}_mae\"] = mae(a, b)\n",
    "                    row[f\"{key_prefix}_psnr\"] = psnr(a, b)\n",
    "            else:\n",
    "                row[f\"{key_prefix}_status\"] = \"missing\"\n",
    "                row[f\"{key_prefix}_mse\"] = \"\"\n",
    "                row[f\"{key_prefix}_mae\"] = \"\"\n",
    "                row[f\"{key_prefix}_psnr\"] = \"\"\n",
    "\n",
    "        writer.writerow(row)\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            print(f\"Processed {i}/{len(stems)}\")\n",
    "\n",
    "print(f\"\\nCSV 저장 완료: {out_csv}\")\n",
    "print(f\"총 처리 파일 수: {len(stems)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fbbff5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125ee05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
